# Autoencoders
В данном ноутбуке содержится реализации разных автоэнкодеров, а именно:
<br>
**1. Vanilla Autoencoder**
<br>
**2. Variational Autoencoder**
<br>
**3. Conditional Variational Autoencoder**
<br>

Способы их применения рассматриваются на датасетах:
<br>
1. **Labelled Faces in the Wild (LFW)**. Этот датасет содержит картинки лиц людей и их атрибуты
<br>
2. **MNIST**. Этот датасет содержит картинки рукописных цифр от 0 до 9.

## Vanilla Autoencoder (AE)

<p align="middle">
	<img src="materials/ae.png">
</p>

Архитектура обычного автоэнкодера будет состоять из энкодера и декодера. Сами энкодер и декодер сформированы следующим образом:
<br>
**nn.Linear > nn.BatchNorm1d > nn.ReLU**
Картинки кодируются в латентные векторы энкодером, из которых потом декодер восстанавливает картинки. Для обучение используется обычная среднеквадратичная ошибка (MSE).

### AE Реконструкции

Автоэнкодер в большинстве случаев восстановил картинки достаточно близко к оригиналам, хотя в некоторых случаях заметны сильные искажения.

<p align="middle">
	<img src="materials/ae_rec.png">
</p>

### AE Sampling
Автоэнкодер может генерировать новые картинки на основании векторов из нормального распределения размерности латентного пространства с небольшими корректировками.

Ниже картинки лиц, которые сгенерировал автоэнкодер. На них можно различить различные черты лиц, пола, эмоций.

<p align="middle">
	<img src="materials/ae_gen.png">
</p>


### Добавление атрибутов на картинку

Автоэнкодер может не только восстанавливать картинки из латентных векторов, но и добавлять атрибуты (например, улыбки).

<p align="middle">
	<img src="materials/ae_smile_add.png">
</p>

## Variational Autoencoder (VAE)

Отличие VAE от обычного AE заключается в так называемом **reparametrization trick**: преобразование, позволяющее перейти от случайной величины, имеющей стандартное нормальное распределение (со средним 0 и дисперсией 1), к произвольной нормальной случайной величине. Такой трюк позволяет генерировать латентный вектор из произвольного нормального распределения.
Для обучения VAE используется датасет с цифрами MNIST.

VAE состоит из энкодера и декодера.
<br>
Архитектура энкодера: **Conv2d > BatchNorm2d > ReLU**
<br>
Декодера: **ConvTranspose2d > BatchNorm2d > ReLU**

Лосс у VAE состоит из двух частей: **KL-divrgence** и **log-likelihood**.
### VAE Реконструкции

VAE хорошо восстанавливает картинки цифр на основании латентных векторов.

<p align="middle">
	<img src="materials/vae_mnist_rec.png">
</p>

### VAE Sampling

Аналогично, как и с обычным AE, VAE моджно передать случайные векторы из нормального распределения и посмотреть, какие картинки получаются:

<p align="middle">
	<img src="materials/vae_mnist_gen.png">
</p>

## Conditional VAE (CVAE)

Conditional VAE — так называется вид автоэнкодера, который позволяет генерировать картинки по заданному условию.

<p align="middle">
	<img src="materials/cvae.jpg">
</p>

<p align="middle">
	<img src="materials/cvae_concat.jpg">
</p>

### CVAE Sampling

Восстановленные CVAE картинки разных классов из одного и того же вектора:

<p align="middle">
	<img src="materials/cvae_mnist_gen.png">
</p>

## Denoising

У автоэнкодеров, кроме сжатия и генерации картинок, есть другие практические применения. Автоэнкодеры могут быть использованы для избавления от шума на фотографиях (denoising). Для этого их нужно обучить специальным образом: входная картинка будет зашумленной, а выдавать автоэнкодер должен будет картинку без шума. 

<p align="middle">
	<img src="materials/denoising.png">
</p>

## Image Retrieval

Также с помощью автоэкнодеров возможно искать похожие изображения. Например, лица. Для этого надо закодировать картинку в латентное представление и сравнить с латентными представлениями картинок в базе данных.

<p align="middle">
	<img src="materials/query.png">
</p>
